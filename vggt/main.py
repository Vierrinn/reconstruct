import os
import cv2
import torch
import open3d as o3d
import numpy as np
from PIL import Image

from vggt.models.vggt import VGGT
from vggt.utils.load_fn import load_and_preprocess_images

device = "cpu"
model = VGGT.from_pretrained("facebook/VGGT-1B").to(device).eval()

# === –ü–∞—Ä–∞–º–µ—Ç—Ä–∏ ===
video_path = "videos/fern.mp4"
frame_output_dir = "imgs"
frame_limit = 4
batch_size = 2

os.makedirs(frame_output_dir, exist_ok=True)

# === 1. –í–∏—Ç—è–≥—É—î–º–æ –∫–∞–¥—Ä–∏ –∑ –≤—ñ–¥–µ–æ ===
cap = cv2.VideoCapture(video_path)
frame_count = 0
print("üéûÔ∏è –í–∏—Ç—è–≥—É—î–º–æ –∫–∞–¥—Ä–∏ –∑ –≤—ñ–¥–µ–æ...")

while cap.isOpened() and frame_count < frame_limit:
    ret, frame = cap.read()
    if not ret:
        break
    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    img_path = os.path.join(frame_output_dir, f"frame_{frame_count}.png")
    Image.fromarray(frame_rgb).save(img_path)
    frame_count += 1
cap.release()
print(f"‚úÖ –ó–±–µ—Ä–µ–∂–µ–Ω–æ {frame_count} –∫–∞–¥—Ä—ñ–≤ —É {frame_output_dir}/")

# === 2. –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —à–ª—è—Ö—ñ–≤ –¥–æ –∫–∞–¥—Ä—ñ–≤ ===
image_paths = sorted([
    os.path.join(frame_output_dir, f)
    for f in os.listdir(frame_output_dir)
    if f.endswith((".png", ".jpg", ".jpeg"))
])

# === 3. –û–±—Ä–æ–±–∫–∞ batch-wise ===
for i in range(0, len(image_paths), batch_size):
    batch_paths = image_paths[i:i+batch_size]
    print(f"üîÑ –û–±—Ä–æ–±–∫–∞ –∫–∞–¥—Ä—ñ–≤ {i}‚Äì{i+len(batch_paths)-1}...")
    
    images = load_and_preprocess_images(batch_paths).to(device)

    with torch.no_grad():
        predictions = model(images)

    print("‚úÖ –Ü–Ω—Ñ–µ—Ä–µ–Ω—Å –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
    print("üîë –ö–ª—é—á—ñ:", predictions.keys())

    # === –í–∏—Ç—è–≥—É—î–º–æ –ø–æ—Ç—Ä—ñ–±–Ω–µ ===
    if all(k in predictions for k in ['point_map', 'depth_map', 'intrinsics', 'extrinsics']):
        point_map = predictions["point_map"].cpu().numpy()         # (B, H, W, 3)
        depth_map = predictions["depth_map"].cpu().numpy()         # (B, H, W)
        intrinsics = predictions["intrinsics"].cpu().numpy()       # (B, 3, 3)
        extrinsics = predictions["extrinsics"].cpu().numpy()       # (B, 4, 4)

        print(f"üìå point_map: {point_map.shape}")
        print(f"üìå depth_map: {depth_map.shape}")
        print(f"üìå intrinsics[0]:\n{intrinsics[0]}")
        print(f"üìå extrinsics[0]:\n{extrinsics[0]}")

        # === –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è point_map ===
        flat_points = point_map.reshape(-1, 3)
        flat_points = flat_points[~np.isnan(flat_points).any(axis=1)]  # —Ñ—ñ–ª—å—Ç—Ä—É—î–º–æ nan
        pcd = o3d.geometry.PointCloud()
        pcd.points = o3d.utility.Vector3dVector(flat_points)
        o3d.visualization.draw_geometries([pcd], window_name="VGGT ‚Äî 3D point_map")

    else:
        print("‚ö†Ô∏è –û–¥–∏–Ω —ñ–∑ –∫–ª—é—á—ñ–≤ –≤—ñ–¥—Å—É—Ç–Ω—ñ–π. –°–ø—Ä–æ–±—É–π —ñ–Ω—à—ñ –∫–∞–¥—Ä–∏ –∞–±–æ –≤—ñ–¥–µ–æ.")
